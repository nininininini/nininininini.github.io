<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>AiMath</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-04-01T03:06:15.321Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Li</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>QA</title>
    <link href="http://yoursite.com/2020/04/01/QA/"/>
    <id>http://yoursite.com/2020/04/01/QA/</id>
    <published>2020-04-01T03:00:47.000Z</published>
    <updated>2020-04-01T03:06:15.321Z</updated>
    
    <content type="html"><![CDATA[<h1 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h1><ol><li>计算问题与库里问题的相似度，怎样表示，怎样评估相似度</li></ol><p>倒排表：有可能相似度很高的，再比较相似度</p><p>过滤掉没有用的Q</p><p>3 </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;计算&quot;&gt;&lt;a href=&quot;#计算&quot; class=&quot;headerlink&quot; title=&quot;计算&quot;&gt;&lt;/a&gt;计算&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;计算问题与库里问题的相似度，怎样表示，怎样评估相似度&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;倒排表：有可能相似度很高的，再比较相似度&lt;/p
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>EM</title>
    <link href="http://yoursite.com/2020/04/01/EM/"/>
    <id>http://yoursite.com/2020/04/01/EM/</id>
    <published>2020-04-01T02:59:40.000Z</published>
    <updated>2020-04-01T02:59:40.087Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文本匹配</title>
    <link href="http://yoursite.com/2020/04/01/%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/"/>
    <id>http://yoursite.com/2020/04/01/%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/</id>
    <published>2020-04-01T01:32:52.000Z</published>
    <updated>2020-04-01T02:59:05.849Z</updated>
    
    <content type="html"><![CDATA[<h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1><ol><li><p>搜索排序</p></li><li><p>客服机器人。很多意图，反馈信息</p><p>从库中找最相似的问题回答</p></li><li><p>机器翻译  衡量句子语义的相似性</p></li><li><p>推荐系统。画像和库中文本比对，推荐排位最高的</p></li></ol><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="string-based"><a href="#string-based" class="headerlink" title="string-based"></a>string-based</h2><p>最长公共子串-LCS</p><h2 id="edit-distance"><a href="#edit-distance" class="headerlink" title="edit distance"></a>edit distance</h2><p>把一串变另外一串的工作量</p><h2 id="Jaro-相似"><a href="#Jaro-相似" class="headerlink" title="Jaro 相似"></a>Jaro 相似</h2><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200401-3.jpg"></p><h2 id="欧式距离"><a href="#欧式距离" class="headerlink" title="欧式距离"></a>欧式距离</h2><h2 id="余弦距离-两个的角度z"><a href="#余弦距离-两个的角度z" class="headerlink" title="余弦距离  两个的角度z"></a>余弦距离  两个的角度z</h2><h2 id="逐点互信息"><a href="#逐点互信息" class="headerlink" title="逐点互信息"></a>逐点互信息</h2><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200401-4.jpg"></p><blockquote><p>两个的信息相关性多大</p></blockquote><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200401-5.jpg"></p><p>字符</p><p>利用全局的量</p><h2 id="单语义文本匹配"><a href="#单语义文本匹配" class="headerlink" title="单语义文本匹配"></a>单语义文本匹配</h2><p>NN，各个句子映射为不同的向量，句子之间没有交互</p><h2 id="多语义文档表达"><a href="#多语义文档表达" class="headerlink" title="多语义文档表达"></a>多语义文档表达</h2><p>从更多粒度衡量相似性</p><p>匹配之前大量交互—局部相似度，不会丢失局部信息</p><p>互相位置运算</p><h2 id="做文档匹配遇到的问题"><a href="#做文档匹配遇到的问题" class="headerlink" title="做文档匹配遇到的问题"></a>做文档匹配遇到的问题</h2><ol><li><p>是否是同性质的文档</p><p>是从不同的问题中找和从不同答案中找</p><p>不同的问题的话需要参数共享  问题和答案匹配的话参数不应该共享</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;应用场景&quot;&gt;&lt;a href=&quot;#应用场景&quot; class=&quot;headerlink&quot; title=&quot;应用场景&quot;&gt;&lt;/a&gt;应用场景&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;搜索排序&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;客服机器人。很多意图，反馈信息&lt;/p&gt;
&lt;p&gt;从库中找最相似的
      
    
    </summary>
    
    
      <category term="nlp" scheme="http://yoursite.com/categories/nlp/"/>
    
    
  </entry>
  
  <entry>
    <title>read-papers</title>
    <link href="http://yoursite.com/2020/03/31/read-papers/"/>
    <id>http://yoursite.com/2020/03/31/read-papers/</id>
    <published>2020-03-30T23:36:42.000Z</published>
    <updated>2020-04-01T01:22:55.436Z</updated>
    
    <content type="html"><![CDATA[<h1 id="mining-and-summarizing-customer"><a href="#mining-and-summarizing-customer" class="headerlink" title="mining and summarizing customer"></a>mining and summarizing customer</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ol><li>提出解决方案</li><li>比较不同</li></ol><h2 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h2><p>前言</p><blockquote><p>对abstract的扩充</p></blockquote><ol><li>展开解决方案</li><li>详细创新点</li><li>详细各执行步骤</li></ol><h1 id="related-work"><a href="#related-work" class="headerlink" title="related work"></a>related work</h1><h1 id="method"><a href="#method" class="headerlink" title="method"></a>method</h1><ol><li><p>POS</p><p>fuzzy matching — word variants  misspelling</p></li><li><p>frequent features identification</p><p>显性特征提取，隐性不能</p></li><li><p>opinion words extration</p><p>情感与语境相关</p></li><li><p>orientation identification</p><p>基于规则</p><p>wordNet  每个词打情感标签</p></li><li><p>抽取不常见属性—规则—名词</p><p>属性词和情感词都抽取</p></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="pros"><a href="#pros" class="headerlink" title="pros"></a>pros</h3><ol><li>提出了一个新任务</li><li>建立有效的系统</li></ol><h3 id="cons"><a href="#cons" class="headerlink" title="cons"></a>cons</h3><ol><li><p>只考虑显性的</p></li><li><p>人工规则</p></li><li><p>没有解决介词</p></li></ol><h1 id="sentiment-analysis-by-capsules"><a href="#sentiment-analysis-by-capsules" class="headerlink" title="sentiment analysis by capsules"></a>sentiment analysis by capsules</h1><h2 id="motivation"><a href="#motivation" class="headerlink" title="motivation"></a>motivation</h2><ol><li><p>nn依赖文本表示</p></li><li><p>语言学知识需要引入进来</p><h1 id="model"><a href="#model" class="headerlink" title="model"></a>model</h1><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200401-0.jpg"></p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200401-1.jpg"></p><h2 id="contribution"><a href="#contribution" class="headerlink" title="contribution"></a>contribution</h2></li><li><p>提出了一个基于capsule的模型</p></li><li><p>不需要语言学知识可以达到很好的效果</p></li><li><p>实验显示鲁棒性</p></li></ol><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>   <img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200401-2.jpg"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;mining-and-summarizing-customer&quot;&gt;&lt;a href=&quot;#mining-and-summarizing-customer&quot; class=&quot;headerlink&quot; title=&quot;mining and summarizing custome
      
    
    </summary>
    
    
      <category term="read paper" scheme="http://yoursite.com/categories/read-paper/"/>
    
    
  </entry>
  
  <entry>
    <title>glove-elmo</title>
    <link href="http://yoursite.com/2020/03/30/glove-elmo/"/>
    <id>http://yoursite.com/2020/03/30/glove-elmo/</id>
    <published>2020-03-30T06:34:47.000Z</published>
    <updated>2020-03-30T15:01:27.017Z</updated>
    
    <content type="html"><![CDATA[<h1 id="词向量"><a href="#词向量" class="headerlink" title="词向量"></a>词向量</h1><h2 id="LSA"><a href="#LSA" class="headerlink" title="LSA"></a>LSA</h2><p>信息检索模型，分析文本中出现词的情况，提取出次与此之间潜在的语义结构，用这种潜在的予以结构表示词和文本（消除词之间的相关性以及简化文本向量实现降维）</p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-10.jpg"></p><p>奇异值分解—降维</p><p>LSA—-LDA</p><h2 id="word2vec"><a href="#word2vec" class="headerlink" title="word2vec"></a>word2vec</h2><p>LSA缺少语境 只考虑在不在同一篇文档</p><p>Word2vec缺少统计信息</p><p>既考虑语境也考虑统计信息—glove</p><h2 id="glove-wi词向量"><a href="#glove-wi词向量" class="headerlink" title="glove   wi词向量"></a>glove   wi词向量</h2><p><a href="https://blog.csdn.net/weixin_36711901/article/details/78508798" target="_blank" rel="noopener">glove理解</a></p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-11.jpg"></p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-12.jpg"></p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-13.jpg"></p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-14.jpg"></p><h2 id="elmo"><a href="#elmo" class="headerlink" title="elmo"></a>elmo</h2><h3 id="预训练词向量需要考虑两个方面"><a href="#预训练词向量需要考虑两个方面" class="headerlink" title="预训练词向量需要考虑两个方面"></a>预训练词向量需要考虑两个方面</h3><ol><li>词的复杂特征—语法和语义</li><li>不同的文本词向量不一样</li></ol><p>语言模型：判断一句话像不像人话</p><blockquote><p>神经概率语言模型—利用神经网络来对语言模型进行建模pytorch</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;词向量&quot;&gt;&lt;a href=&quot;#词向量&quot; class=&quot;headerlink&quot; title=&quot;词向量&quot;&gt;&lt;/a&gt;词向量&lt;/h1&gt;&lt;h2 id=&quot;LSA&quot;&gt;&lt;a href=&quot;#LSA&quot; class=&quot;headerlink&quot; title=&quot;LSA&quot;&gt;&lt;/a&gt;LSA&lt;/h
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>noisy-channel-model-语言模型</title>
    <link href="http://yoursite.com/2020/03/30/noisy-channel-model-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    <id>http://yoursite.com/2020/03/30/noisy-channel-model-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</id>
    <published>2020-03-30T01:36:30.000Z</published>
    <updated>2020-03-30T06:34:27.408Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-2.jpg"></p><h2 id="LM-语言模型用来判断是否一句话从语法上通顺"><a href="#LM-语言模型用来判断是否一句话从语法上通顺" class="headerlink" title="LM : 语言模型用来判断是否一句话从语法上通顺"></a>LM : 语言模型用来判断是否一句话从语法上通顺</h2><p>根据模型参数可以计算出概率 </p><p>chain rule for LM</p><h3 id="Markov-assumption—-减少复杂度"><a href="#Markov-assumption—-减少复杂度" class="headerlink" title="Markov assumption—-减少复杂度"></a>Markov assumption—-减少复杂度</h3><ol><li><p>只考虑最相近的信息，基于太远的信息影响对当前信息影响不大</p></li><li><p>bigram, trigram, 4-gram</p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-3.jpg"></p></li></ol><h3 id="LSTM-从前往后，不能理解一个词在前后的意思（X-Net）"><a href="#LSTM-从前往后，不能理解一个词在前后的意思（X-Net）" class="headerlink" title="LSTM 从前往后，不能理解一个词在前后的意思（X-Net）"></a>LSTM 从前往后，不能理解一个词在前后的意思（X-Net）</h3><blockquote><p><font color=red>CRF前后都考虑</font></p></blockquote><p>unigram 不考虑上下文信息，两个句子顺序不同概率一样</p><p>n-gram 会有稀疏问题——解决：分布表示（深度学习）</p><p>训练时统计的过程</p><p>思考：不放在特定的任务中验证语言模型的好坏？</p><p>评估语言模型</p><p>perplexity： 大于0的一个值</p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-4.jpg"></p><p>信息混淆程度，越小越好</p><p><font color=red>为什么2次方？当前模型去离合测试集的不确定性大小？</font></p><p><font color=blue>LDA也可以计算perplexity，生成式的都可以计算perplexity</font></p><p>个别概率为0，导致整个概率为0—-需要smoothing</p><p>训练集中不存在不确定测试集中不出现—我看到的不一定是我知道所有东西。</p><h2 id="smoothing—–统计得到"><a href="#smoothing—–统计得到" class="headerlink" title="smoothing—–统计得到"></a>smoothing—–统计得到</h2><ol><li><p>Add-one smoothing—laplace smoothing</p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-5.jpg"></p><p>加v保证概率和为1</p></li><li><p>Add-k smoothing</p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-6.jpg"></p></li><li><p>interpolation</p><p>unigram 的信息也很重要，既要考虑bigram也要考虑unigram</p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-7.jpg"></p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-8.jpg"></p></li><li><p>Good-turning smoothing</p><p>给定可能出现的词一定的概率，所以要变化已有词的概率</p><p>N1：出现一次的单词个数</p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-9.jpg"></p></li></ol><blockquote><p>不存在的用模型预测值</p><p><font color=red>平滑可以看成是贝叶斯的特例</font></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/&quot; alt=&quot;&quot; class=&quot;lazyload&quot; data-src=&quot;/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-2.jpg&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;LM-语言模型用来判断是否一句话从语法上通顺&quot;&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>句子相似度</title>
    <link href="http://yoursite.com/2020/03/29/%E5%8F%A5%E5%AD%90%E7%9B%B8%E4%BC%BC%E5%BA%A6/"/>
    <id>http://yoursite.com/2020/03/29/%E5%8F%A5%E5%AD%90%E7%9B%B8%E4%BC%BC%E5%BA%A6/</id>
    <published>2020-03-29T15:38:13.000Z</published>
    <updated>2020-04-01T03:00:35.305Z</updated>
    
    <content type="html"><![CDATA[<h1 id="句子相似度"><a href="#句子相似度" class="headerlink" title="句子相似度"></a>句子相似度</h1><ol><li><p>余弦相似度</p></li><li><p>欧式距离</p></li><li><p>绝对距离</p></li><li><p>minkobxki pister   p次方 1/p</p></li><li><p>mahalanlkis distance   映射到另外一个空间，转换的方法是线性的</p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200329-3.jpg"></p></li><li><p>kernel distance：  kernal funtion 之后的距离</p></li></ol><p>TF-IDF</p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200330-0.jpg"></p><h2 id="词之间的相似度"><a href="#词之间的相似度" class="headerlink" title="词之间的相似度"></a>词之间的相似度</h2><blockquote><ol><li><p>one-hot 是无法计算词之间的相似度—–所以用到词向量的方法（distributed representation）</p></li><li><p>使用词向量的方法表示后就可以用余弦相似度来计算两个词之间的相似度了</p></li><li><p>分布式表示（词向量）</p><p>单词—向量   句子—向量  网络—向量  代码模块—向量    <font color=blue>embedding</font></p></li><li><p>学习词向量</p><p>. 不考虑上下文        glove， skip-gram</p><p>. 考虑上下文的        context-aware—bert， elmo</p></li><li><p>有了词向量之后可以画图</p><p><font color=red>T-SNE算法  降维</font>   </p><p><font color=red>欧式空间，黎曼空间中学习</font></p></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;句子相似度&quot;&gt;&lt;a href=&quot;#句子相似度&quot; class=&quot;headerlink&quot; title=&quot;句子相似度&quot;&gt;&lt;/a&gt;句子相似度&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;余弦相似度&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;欧式距离&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;绝对距离
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>拼写错误纠正</title>
    <link href="http://yoursite.com/2020/03/29/%E6%8B%BC%E5%86%99%E9%94%99%E8%AF%AF%E7%BA%A0%E6%AD%A3/"/>
    <id>http://yoursite.com/2020/03/29/%E6%8B%BC%E5%86%99%E9%94%99%E8%AF%AF%E7%BA%A0%E6%AD%A3/</id>
    <published>2020-03-29T13:51:25.000Z</published>
    <updated>2020-03-29T15:10:13.022Z</updated>
    
    <content type="html"><![CDATA[<h2 id="错误种类"><a href="#错误种类" class="headerlink" title="错误种类"></a>错误种类</h2><h3 id="错别字"><a href="#错别字" class="headerlink" title="错别字"></a>错别字</h3><ol><li><p>改过来</p></li><li><p>寻找：</p></li><li><p>基于用户的输入，候选的单词列出来（词库排序），看哪个是最好的（编辑距离最小—需要几个单位的操作； hang distance 二进制距离）</p><p>改进的方法是生成编辑距离为1，2 的字符串，过滤，返回（<font color=red>数据增强过滤-语言模型找概率最大的</font>）</p><p>怎么过滤：候选词然后用语言模型计算概率，找概率最大的。</p><p>给定字符串s，找出最有可能正确的字符串c</p><p>noisy chanel model</p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/QQ20200329-1.jpg"></p></li></ol><blockquote><p><font color=red>写错的概率和语言模型的概率，可以分别训练，然后融合模型</font></p><p>语言模型可以看成是先验概率</p></blockquote><h3 id="语法错误"><a href="#语法错误" class="headerlink" title="语法错误"></a>语法错误</h3><p>可以通过语言模型的方式解决，计算词组的概率</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;错误种类&quot;&gt;&lt;a href=&quot;#错误种类&quot; class=&quot;headerlink&quot; title=&quot;错误种类&quot;&gt;&lt;/a&gt;错误种类&lt;/h2&gt;&lt;h3 id=&quot;错别字&quot;&gt;&lt;a href=&quot;#错别字&quot; class=&quot;headerlink&quot; title=&quot;错别字&quot;&gt;&lt;/a&gt;错别
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文本表示基础</title>
    <link href="http://yoursite.com/2020/03/29/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA%E5%9F%BA%E7%A1%80/"/>
    <id>http://yoursite.com/2020/03/29/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA%E5%9F%BA%E7%A1%80/</id>
    <published>2020-03-29T07:42:59.000Z</published>
    <updated>2020-03-29T15:10:21.640Z</updated>
    
    <content type="html"><![CDATA[<h1 id="segmentation-method"><a href="#segmentation-method" class="headerlink" title="segmentation method"></a>segmentation method</h1><h2 id="max-matching"><a href="#max-matching" class="headerlink" title="max matching"></a>max matching</h2><ol><li><p>Forward-max matching： 一种贪心算法</p><p>词典中每次匹配的单词的长度是最大的</p><blockquote><p>定义max-length, 逐渐匹配词典里的词，有匹配则划线分词</p></blockquote></li><li><p>backward-max matching： 与前向相反（90%是一样的）</p></li></ol><blockquote><p>缺点：（贪心算法）</p><ol><li>未必选择长度最大的是最优的</li><li>只是参考词典，没有考虑词的语义</li></ol></blockquote><blockquote><p>解决：设计算法，考虑语义（合成语义）</p><ol><li>不同的分割，哪种更好—-结合语言模型, 不同句子的概率    n-gram</li><li>找出所有分割方式，希望可以在多项式时间内实现这个过程</li><li>输入—-所有分割—选择其中最好的（概率最大）</li></ol></blockquote><h2 id="？-inference—viterbi-estimation"><a href="#？-inference—viterbi-estimation" class="headerlink" title="？ inference—viterbi  estimation"></a>？ inference—viterbi  estimation</h2><p>假定每个词的概率已知</p><p>给定每个词的概率，寻找最短路径</p><p>Dp是循环的方式，所有的表填满计算  -log(p(x))（<font color=blue>最大变最小，乘变加</font>）</p><p><img src="/" alt="维特比算法" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/EF4CC2D5-B3AB-4380-8E1E-59C003CA3024.png"></p><blockquote><p> viterbi是一种dp</p><p> viterbi也用来做inference：</p><p>模型已知的情况下，预测隐变量？</p></blockquote><h2 id=""><a href="#" class="headerlink" title=""></a></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;segmentation-method&quot;&gt;&lt;a href=&quot;#segmentation-method&quot; class=&quot;headerlink&quot; title=&quot;segmentation method&quot;&gt;&lt;/a&gt;segmentation method&lt;/h1&gt;&lt;h2 i
      
    
    </summary>
    
    
      <category term="nlp-深度之眼" scheme="http://yoursite.com/categories/nlp-%E6%B7%B1%E5%BA%A6%E4%B9%8B%E7%9C%BC/"/>
    
    
      <category term="segmentation method" scheme="http://yoursite.com/tags/segmentation-method/"/>
    
  </entry>
  
  <entry>
    <title>Adam</title>
    <link href="http://yoursite.com/2020/03/29/Adam/"/>
    <id>http://yoursite.com/2020/03/29/Adam/</id>
    <published>2020-03-29T03:18:34.000Z</published>
    <updated>2020-03-29T03:21:51.345Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="nlp-深度之眼" scheme="http://yoursite.com/categories/nlp-%E6%B7%B1%E5%BA%A6%E4%B9%8B%E7%9C%BC/"/>
    
    
  </entry>
  
  <entry>
    <title>paper</title>
    <link href="http://yoursite.com/2020/03/29/paper/"/>
    <id>http://yoursite.com/2020/03/29/paper/</id>
    <published>2020-03-29T03:12:55.000Z</published>
    <updated>2020-03-29T03:12:55.923Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>第一章线性规划与单纯形法</title>
    <link href="http://yoursite.com/2020/03/29/%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92%E4%B8%8E%E5%8D%95%E7%BA%AF%E5%BD%A2%E6%B3%95/"/>
    <id>http://yoursite.com/2020/03/29/%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92%E4%B8%8E%E5%8D%95%E7%BA%AF%E5%BD%A2%E6%B3%95/</id>
    <published>2020-03-29T00:54:03.000Z</published>
    <updated>2020-03-29T03:08:25.388Z</updated>
    
    <content type="html"><![CDATA[<h1 id="化标准型"><a href="#化标准型" class="headerlink" title="化标准型"></a>化标准型</h1><p>价值系数c，工艺或技术系数a，资源限制b，决策变量约束x</p><p>建模思路：</p><ol><li><p>确定决策变量—很重要很难</p></li><li><p>写出目标函数</p></li><li><p>找出约束条件</p></li></ol><p>线性规划的标准型：</p><ol><li>目标函数最大化： 若是最小化，则零目标函数前加符号，</li><li>约束条件等式：若是小于等于加上一个松弛变量，若是大于等于减去一个剩余变量</li><li>决策变量非负： 若小于等于0，替换变量，若无约束x’-x”</li><li>资源限量非负：两边加符号</li></ol><blockquote><p>松弛变量和剩余变量在实际问题中分别表示未被充分利用和超出的资源数， 均为转化为价值和利润，所以引入模型后它们在目标函数中的系数为0</p><p>化标准型是单纯化求解的基础</p></blockquote><h2 id="图解法"><a href="#图解法" class="headerlink" title="图解法"></a>图解法</h2><p>可行域，目标函数z平移</p><p><img src="/" alt="图解法" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/%E5%9B%BE%E8%A7%A3%E6%B3%95.png"></p><h2 id="单纯形法"><a href="#单纯形法" class="headerlink" title="单纯形法"></a>单纯形法</h2><h3 id="单纯形法的原理"><a href="#单纯形法的原理" class="headerlink" title="单纯形法的原理"></a>单纯形法的原理</h3><blockquote><p>可行解 满足约束条件的所有解–可行域</p></blockquote><p><img src="/" alt="概念" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/%E9%97%AE%E9%A2%98%E8%A7%A3%E7%9A%84%E6%A6%82%E5%BF%B5.png"></p><p><img src="/" alt="可行基" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/A0CE8255-ED99-489F-9008-63B2B77DBA77.png"></p><h3 id="几点结论："><a href="#几点结论：" class="headerlink" title="几点结论："></a>几点结论：</h3><ol><li>可行域若有界则是凸集，也可能是无界域</li><li>每个基可行解对应可行域的一个顶点</li><li>可行域有有限多个顶点</li><li>如果有最优解，必在某个顶点上得到</li></ol><p><img src="/" alt="解之间的关系" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/E80FFD0A-B5A1-4851-90C2-CB5998FF81A4.png"></p><h3 id="单纯形法迭代原理"><a href="#单纯形法迭代原理" class="headerlink" title="单纯形法迭代原理"></a>单纯形法迭代原理</h3><p><img src="/" alt="基变换" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/E3583982-A80E-4D6B-9760-99015E7E6B1C.png"></p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/E3583982-A80E-4D6B-9760-99015E7E6B1C.png"></p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/E3583982-A80E-4D6B-9760-99015E7E6B1C.png"></p><p><img src="/" alt="" class="lazyload" data-src="/Users/doouni/qq%E5%9B%BE%E7%89%87/643304D9-2806-422C-BBD5-4F920F1C29F5.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;化标准型&quot;&gt;&lt;a href=&quot;#化标准型&quot; class=&quot;headerlink&quot; title=&quot;化标准型&quot;&gt;&lt;/a&gt;化标准型&lt;/h1&gt;&lt;p&gt;价值系数c，工艺或技术系数a，资源限制b，决策变量约束x&lt;/p&gt;
&lt;p&gt;建模思路：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;确定决策
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>线性规划</title>
    <link href="http://yoursite.com/2020/03/28/%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92/"/>
    <id>http://yoursite.com/2020/03/28/%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92/</id>
    <published>2020-03-28T14:52:23.000Z</published>
    <updated>2020-03-29T00:37:55.190Z</updated>
    
    <content type="html"><![CDATA[<h1 id="定义：线性约束条件下线性目标函数的极值问题（最优决策）"><a href="#定义：线性约束条件下线性目标函数的极值问题（最优决策）" class="headerlink" title="定义：线性约束条件下线性目标函数的极值问题（最优决策）"></a>定义：线性约束条件下线性目标函数的极值问题（最优决策）</h1><h1 id="特点："><a href="#特点：" class="headerlink" title="特点："></a>特点：</h1><ol><li>可行域总是一个凸集</li><li>目标函数的一个可行解（包括最优解）一定出现在可行域的一个顶点上</li></ol><blockquote><p>有限的资源和若干竞争约束下的目标函数最大或最小化的最优策略</p></blockquote><blockquote><p>线性规划可以写成标准形式</p><p>松弛型—加入变量让不等约束变为等式约束</p></blockquote><p><img src="/" alt="单纯形算法" class="lazyload" data-src="http://m.qpic.cn/psc?/V11AnIAP0yjLkE/cX4Vyn98zHAGUajflo5h*OEd6dZYRWy2HDnRhX.f2DMcLieHxFHm4XyBztK.jwv47sCWZtSikQb21e2IUgfikg!!/b&bo=oAU4BAAAAAARB6k!&rf=viewer_4"></p><blockquote><p>用约束比较强的去替换 （常数项最小？）</p><p>若目标函数没有系数为负数的项了，说明无法再继续减小目标函数，算法达到了收敛，停止转动</p></blockquote><h2 id="避免退化–bland规则"><a href="#避免退化–bland规则" class="headerlink" title="避免退化–bland规则"></a>避免退化–bland规则</h2><p>原因：替入替出变量选择不当，算法循环旋转不停止。</p><p>退化是导致单纯算法不会收敛的唯一原因</p><h3 id="bland规则：-在选择替入变量和替出变量的时候，总是选择满足条件的下标最小值"><a href="#bland规则：-在选择替入变量和替出变量的时候，总是选择满足条件的下标最小值" class="headerlink" title="bland规则： 在选择替入变量和替出变量的时候，总是选择满足条件的下标最小值"></a>bland规则： 在选择替入变量和替出变量的时候，总是选择满足条件的下标最小值</h3><p><img src="/" alt="完整步骤" class="lazyload" data-src="http://m.qpic.cn/psc?/V11AnIAP0yjLkE/cX4Vyn98zHAGUajflo5h*PpxxDMvHFYmyNlhu5VNEMas.UegDCKPY6Hz8z49ISfuZ19AKd.1hzTRNz7xOXye2g!!/b&bo=oAU4BAAAAAARB6k!&rf=viewer_4"></p><h2 id="线性规划的对偶"><a href="#线性规划的对偶" class="headerlink" title="线性规划的对偶"></a>线性规划的对偶</h2><p>. 对偶问题的最优解相等</p><p>原因：</p><ol><li>有时候对偶问题比原问题简单（原问题约束多，变量少）</li><li>单纯形算法初始基本可行解找不到</li><li>便于进行敏感度分析（如果某些已知条件发生变化，对最优解的影响程度如何）</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;定义：线性约束条件下线性目标函数的极值问题（最优决策）&quot;&gt;&lt;a href=&quot;#定义：线性约束条件下线性目标函数的极值问题（最优决策）&quot; class=&quot;headerlink&quot; title=&quot;定义：线性约束条件下线性目标函数的极值问题（最优决策）&quot;&gt;&lt;/a&gt;定义：线性
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>凸优化</title>
    <link href="http://yoursite.com/2020/03/24/%E5%87%B8%E4%BC%98%E5%8C%96/"/>
    <id>http://yoursite.com/2020/03/24/%E5%87%B8%E4%BC%98%E5%8C%96/</id>
    <published>2020-03-24T08:04:51.000Z</published>
    <updated>2020-03-24T08:07:54.817Z</updated>
    
    <content type="html"><![CDATA[<h1 id="几种不同的函数"><a href="#几种不同的函数" class="headerlink" title="几种不同的函数"></a>几种不同的函数</h1><h2 id="凸函数"><a href="#凸函数" class="headerlink" title="凸函数"></a>凸函数</h2><p>1.</p><p>2.</p><h2 id="拉帕朗斯函数"><a href="#拉帕朗斯函数" class="headerlink" title="拉帕朗斯函数"></a>拉帕朗斯函数</h2><h2 id="平滑"><a href="#平滑" class="headerlink" title="平滑"></a>平滑</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;几种不同的函数&quot;&gt;&lt;a href=&quot;#几种不同的函数&quot; class=&quot;headerlink&quot; title=&quot;几种不同的函数&quot;&gt;&lt;/a&gt;几种不同的函数&lt;/h1&gt;&lt;h2 id=&quot;凸函数&quot;&gt;&lt;a href=&quot;#凸函数&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
    
      <category term="ml" scheme="http://yoursite.com/categories/ml/"/>
    
    
      <category term="nlp" scheme="http://yoursite.com/tags/nlp/"/>
    
      <category term="ml" scheme="http://yoursite.com/tags/ml/"/>
    
  </entry>
  
  <entry>
    <title>study</title>
    <link href="http://yoursite.com/2020/03/24/study/"/>
    <id>http://yoursite.com/2020/03/24/study/</id>
    <published>2020-03-24T02:19:37.000Z</published>
    <updated>2020-03-24T02:49:57.624Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2020/03/24/hello-world/"/>
    <id>http://yoursite.com/2020/03/24/hello-world/</id>
    <published>2020-03-24T01:08:57.265Z</published>
    <updated>2020-03-24T07:52:46.093Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><a id="more"></a><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files-1"><a href="#Generate-static-files-1" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;&lt;h3 id=&quot;Create-a-new-post&quot;&gt;&lt;a href=&quot;#Create-a-new-post&quot; class=&quot;headerlink&quot; title=&quot;Create a new post&quot;&gt;&lt;/a&gt;Create a new post&lt;/h3&gt;&lt;p&gt;More info: &lt;a href=&quot;https://hexo.io/docs/server.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Server&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
</feed>
